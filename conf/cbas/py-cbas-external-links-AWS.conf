cbas.cbas_external_links_AWS_S3.CBASExternalLinks:
    test_create_external_link
    test_create_external_link,dataverse=3,link=5
    test_list_external_links
    #NAtest_alter_link_properties
    test_connect_link
    test_disconnect_link
    test_create_dataset
    
    # run successful query
    test_query_dataset,default_bucket=True,file_format=json,file_format_for_upload=["json"]
    test_query_dataset,default_bucket=True,file_format=csv,header=False,object_construction_def=filename STRING, folder STRING, mutated INT, null_key STRING, missing_field INT,file_format_for_upload=["csv"]
    test_query_dataset,default_bucket=True,file_format=tsv,header=False,object_construction_def=filename STRING, folder STRING, mutated INT, null_key STRING, missing_field INT,file_format_for_upload=["tsv"]
    
    # query from a file which has mix of data
    test_query_dataset,default_bucket=True,file_format=json,file_format_for_upload=["json"], mix_data_file=True,validate_error_conditions=True
    test_query_dataset,default_bucket=True,file_format=csv,header=False,object_construction_def=key1 STRING, key2 STRING, key3 STRING, key4 STRING,file_format_for_upload=["csv"], mix_data_file=True,expected_count=1
    test_query_dataset,default_bucket=True,file_format=tsv,header=False,object_construction_def=key1 STRING, key2 STRING, key3 STRING, key4 STRING,file_format_for_upload=["tsv"], mix_data_file=True,expected_count=1
    
    #query from a mix of json, csv and tsv files
    test_query_dataset,default_bucket=True,file_format=json,file_format_for_upload=["json","csv","tsv"],validate_error_conditions=True
    test_query_dataset,default_bucket=True,file_format=csv,header=False,object_construction_def=filename STRING, folder STRING, mutated INT, null_key STRING, missing_field INT,file_format_for_upload=["json","csv","tsv"],n1ql_query=select * from {0} where filename like "%.csv";
    test_query_dataset,default_bucket=True,file_format=tsv,header=False,object_construction_def=filename STRING, folder STRING, mutated INT, null_key STRING, missing_field INT,file_format_for_upload=["json","csv","tsv"],n1ql_query=select * from {0} where filename like "%.tsv";
    
    # quey from a file that has right data but wrong file externsion
    test_query_dataset,default_bucket=True,file_format=json,file_extension=csv,expected_count=1
    test_query_dataset,default_bucket=True,file_format=csv,file_extension=tsv,expected_count=1,header=False,object_construction_def=key1 STRING, key2 STRING, key3 STRING, key4 STRING,file_format_for_upload=["csv"]
    test_query_dataset,default_bucket=True,file_format=tsv,file_extension=json,expected_count=1,header=False,object_construction_def=key1 STRING, key2 STRING, key3 STRING, key4 STRING,file_format_for_upload=["tsv"]
    
    # query to test include flag
    test_query_dataset,default_bucket=True,file_format=json,file_format_for_upload=["json","csv","tsv"],n1ql_query="select count(*) from {0} where filename like '%.json';",include=["file_[1234567890].json","*.json"]
    test_query_dataset,default_bucket=True,file_format=csv,header=False,object_construction_def=filename STRING, folder STRING, mutated INT, null_key STRING, missing_field INT,file_format_for_upload=["json","csv","tsv"],n1ql_query="select count(*) from {0} where filename like '%.csv';",include=["file_[1234567890].csv","*.csv"]
    test_query_dataset,default_bucket=True,file_format=tsv,header=False,object_construction_def=filename STRING, folder STRING, mutated INT, null_key STRING, missing_field INT,file_format_for_upload=["json","csv","tsv"],n1ql_query="select count(*) from {0} where filename like '%.tsv';",include=["file_[1234567890].tsv","*.tsv"]
    test_query_dataset,default_bucket=True,file_format=json,file_format_for_upload=["json","csv","tsv"],n1ql_query="select count(*) from {0} where filename like '%.json';",include=file_?.[!ct]s[!v]*
    test_query_dataset,default_bucket=True,file_format=csv,header=False,object_construction_def=filename STRING, folder STRING, mutated INT, null_key STRING, missing_field INT,file_format_for_upload=["json","csv","tsv"],n1ql_query="select count(*) from {0} where filename like '%.csv';",include=file_?.[!t]sv
    test_query_dataset,default_bucket=True,file_format=tsv,header=False,object_construction_def=filename STRING, folder STRING, mutated INT, null_key STRING, missing_field INT,file_format_for_upload=["json","csv","tsv"],n1ql_query="select count(*) from {0} where filename like '%.tsv';",include=file_?.[!c]sv
    
    # query to test exclude flag
    test_query_dataset,default_bucket=True,file_format=json,file_format_for_upload=["json","csv","tsv"],n1ql_query="select count(*) from {0} where filename like '%.json';",exclude=exclude=["*.csv","*.tsv"]
    test_query_dataset,default_bucket=True,file_format=csv,header=False,object_construction_def=filename STRING, folder STRING, mutated INT, null_key STRING, missing_field INT,file_format_for_upload=["json","csv","tsv"],n1ql_query="select count(*) from {0} where filename like '%.csv';",exclude=["*.json","*.tsv"]
    test_query_dataset,default_bucket=True,file_format=tsv,header=False,object_construction_def=filename STRING, folder STRING, mutated INT, null_key STRING, missing_field INT,file_format_for_upload=["json","csv","tsv"],n1ql_query="select count(*) from {0} where filename like '%.tsv';",exclude=["*.json","*.csv"]
    test_query_dataset,default_bucket=True,file_format=json,file_format_for_upload=["json","csv","tsv"],n1ql_query="select count(*) from {0} where filename like '%.json';",exclude=file_?*.[ct]s[!o]
    test_query_dataset,default_bucket=True,file_format=csv,header=False,object_construction_def=filename STRING, folder STRING, mutated INT, null_key STRING, missing_field INT,file_format_for_upload=["json","csv","tsv"],n1ql_query="select count(*) from {0} where filename like '%.csv';",exclude=file_?*.[t]s[!v]
    test_query_dataset,default_bucket=True,file_format=tsv,header=False,object_construction_def=filename STRING, folder STRING, mutated INT, null_key STRING, missing_field INT,file_format_for_upload=["json","csv","tsv"],n1ql_query="select count(*) from {0} where filename like '%.tsv';",exclude=file_?*.[c]s[!v]
    

    test_effect_of_rbac_role_change_on_external_link, default_bucket=True
    test_querying_while_network_failure, default_bucket=True
    test_querying_with_more_than_1000_files_in_S3_bucket, default_bucket=True
    test_file_deletion_from_AWS_while_query_is_reading_file,default_bucket=True,no_of_files=1,no_of_docs=100000
    test_file_deletion_from_AWS_while_query_is_reading_file,default_bucket=True,no_of_files=5, no_of_docs=100000, delete_last_file=True
    test_file_deletion_from_AWS_while_query_is_reading_file,default_bucket=True,no_of_files=5, no_of_docs=100000, delete_last_file=True,recreate=True
    test_analytics_cluster_when_rebalancing_in_cbas_node,default_bucket=True
    test_analytics_cluster_swap_rebalancing,default_bucket=True
    test_analytics_cluster_when_rebalancing_out_cbas_node,default_bucket=True
    test_fail_over_cbas_node_followed_by_rebalance_out_or_add_back,default_bucket=True,rebalance_out=False
    test_fail_over_cbas_node_followed_by_rebalance_out_or_add_back,default_bucket=True,rebalance_out=True
    test_fail_over_cbas_node_followed_by_rebalance_out_or_add_back,default_bucket=True,rebalance_out=False,recovery_strategy=full
    test_fail_over_cbas_node_followed_by_rebalance_out_or_add_back,default_bucket=True,rebalance_out=True,recovery_strategy=delta
    test_when_a_single_record_size_is_greater_than_32MB,default_bucket=True,file_format=json,record_size=32
    test_when_a_single_record_size_is_greater_than_32MB,default_bucket=True,file_format=csv,record_size=32
    test_when_a_single_record_size_is_greater_than_32MB,default_bucket=True,file_format=tsv,record_size=32
    test_when_a_single_record_size_is_greater_than_32MB,default_bucket=True,file_format=json,record_size=30
    test_when_a_single_record_size_is_greater_than_32MB,default_bucket=True,file_format=csv,record_size=30
    test_when_a_single_record_size_is_greater_than_32MB,default_bucket=True,file_format=tsv,record_size=30
    test_large_file,file_format=tsv
    test_large_file,file_format=csv
    test_large_file,file_format=json
    
    
    
    